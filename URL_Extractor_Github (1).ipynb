{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "conn = pyodbc.connect(\"DSN=Your Hadoop Cluster Name\", autocommit = True)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"show tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_sql(\"SELECT * FROM table WHERE SRC_CRE_DT BETWEEN TO_DATE('2020-03-20') AND TO_DATE('2020-09-05') \", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the `pyodbc` package:\n",
    "import pyodbc\n",
    "import urllib\n",
    "import getpass\n",
    "\n",
    "# import python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rcParams\n",
    "import seaborn as sb\n",
    "from pandas import DataFrame\n",
    "from collections import defaultdict \n",
    "\n",
    "import re`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSG_Cleaned'] = df['MSG'].astype(str).str.replace('[=^&,_;:,!()#-]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSG_Cleaned'] = df['MSG_Cleaned'].astype(str).replace('[^a-zA-Z0-9./&&[^$@%]', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSG_Cleaned'] = df['MSG_Cleaned'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Email'] =df['MSG_Cleaned'].astype(str).str.findall('[\\w\\.-]+@[\\w\\.-]+\\.\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting email address\n",
    "\n",
    "email_filter_1= (df['Email'].astype(str) == '[]') #Boolen index - Change to str format, filter out [] empty value\n",
    "email_filter_2 = df['Email'].astype(str).str.contains(pat='@members.ebay.com') #Change to str format, filter out ebay subscribe emails\n",
    "\n",
    "df['Email_Cleaned']=\"\"  # Create one new column to store only valid emails\n",
    "df.loc[(email_filter_1==False) & (email_filter_2==False),'Email_Cleaned']= df['Email']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #extracting all the URLs present\n",
    "    \n",
    "    from urlextract import URLExtract\n",
    "    extractor = URLExtract(extract_email=False, cache_dns=True, extract_localhost=True, limit=10000)\n",
    "    x = []\n",
    "    i = 0\n",
    "    while i < len(df['MSG']):\n",
    "        x.append(extractor.find_urls(df['MSG'][i],only_unique=True, check_dns=False))\n",
    "        i = i+1\n",
    "        ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = pd.Series(x)\n",
    "df['new_col'] = se.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#excluding some valid urls\n",
    "\n",
    "url_filter_1 = (df[\"new_col\"].astype(str).astype(str) == '[]')\n",
    "url_filter_2 = (df[\"new_col\"].astype(str).str.contains('usps',case=False))\n",
    "url_filter_3 = (df[\"new_col\"].astype(str).str.contains('fedex',case=False))\n",
    "url_filter_4 = (df[\"new_col\"].astype(str).str.contains('ups',case=False))\n",
    "url_filter_5 = (df[\"new_col\"].astype(str).str.contains('dhl',case=False))\n",
    "url_filter_6 = (df[\"new_col\"].astype(str).str.contains('ebay',case=False))\n",
    "url_filter_7 = (df[\"new_col\"].astype(str).str.contains('auspost',case=False))\n",
    "url_filter_8 = (df[\"new_col\"].astype(str).str.contains('shipstation',case=False))\n",
    "url_filter_9 = (df[\"new_col\"].astype(str).str.contains('mandrillapp.',case=False))\n",
    "url_filter_10 = (df[\"new_col\"].astype(str).str.contains('aftership',case=False))\n",
    "url_filter_11 = (df[\"new_col\"].astype(str).str.contains('overnight',case=False))\n",
    "url_filter_12 = (df[\"new_col\"].astype(str).str.contains('teapplix',case=False))\n",
    "url_filter_13 = (df[\"new_col\"].astype(str).str.contains('stamps',case=False))\n",
    "url_filter_14 = (df[\"new_col\"].astype(str).str.contains('endicia',case=False))\n",
    "url_filter_15 = (df[\"new_col\"].astype(str).str.contains('3dsellers',case=False))\n",
    "url_filter_16 = (df[\"new_col\"].astype(str).str.contains('parcelsapp',case=False))\n",
    "url_filter_17 = (df[\"new_col\"].astype(str).str.contains('17track',case=False))\n",
    "url_filter_18 = (df[\"new_col\"].astype(str).str.contains('shippingeasy',case=False))\n",
    "url_filter_19 = (df[\"new_col\"].astype(str).str.contains('japanpost',case=False))\n",
    "url_filter_20 = (df[\"new_col\"].astype(str).str.contains('chronopost',case=False))\n",
    "url_filter_21 = (df[\"new_col\"].astype(str).str.contains('trackmyshipment',case=False))\n",
    "url_filter_22 = (df[\"new_col\"].astype(str).str.contains('dpd',case=False))\n",
    "url_filter_23 = (df[\"new_col\"].astype(str).str.contains('freightquote',case=False))\n",
    "url_filter_24 = (df[\"new_col\"].astype(str).str.contains('canadapost',case=False))\n",
    "url_filter_25 = (df[\"new_col\"].astype(str).str.contains('parcelmonkey',case=False))\n",
    "url_filter_26 = (df[\"new_col\"].astype(str).str.contains('parcelforce',case=False))\n",
    "url_filter_27 = (df[\"new_col\"].astype(str).str.contains('parcel2go',case=False))\n",
    "url_filter_28 = (df[\"new_col\"].astype(str).str.contains('package',case=False))\n",
    "url_filter_29 = (df[\"new_col\"].astype(str).str.contains('lowcostparcels',case=False))\n",
    "url_filter_30 = (df[\"new_col\"].astype(str).str.contains('poste.it',case=False))\n",
    "\n",
    "df['URL_Cleaned_v2']=\"\"  # Create one new column to store only valid emails\n",
    "df.loc[\n",
    "       (url_filter_1==False) \n",
    "     & (url_filter_2==False) \n",
    "     & (url_filter_3==False) \n",
    "     & (url_filter_4==False) \n",
    "     & (url_filter_5==False)\n",
    "     & (url_filter_6==False)\n",
    "     & (url_filter_7==False)\n",
    "     & (url_filter_8==False)\n",
    "     & (url_filter_9==False)\n",
    "     & (url_filter_10==False)\n",
    "     & (url_filter_11==False)\n",
    "     & (url_filter_12==False)\n",
    "     & (url_filter_13==False)\n",
    "     & (url_filter_14==False)\n",
    "     & (url_filter_15==False)\n",
    "     & (url_filter_16==False)\n",
    "     & (url_filter_17==False)\n",
    "     & (url_filter_18==False)\n",
    "     & (url_filter_19==False)\n",
    "     & (url_filter_20==False)\n",
    "     & (url_filter_21==False)\n",
    "     & (url_filter_22==False)\n",
    "     & (url_filter_23==False)\n",
    "     & (url_filter_24==False)\n",
    "     & (url_filter_25==False)\n",
    "     & (url_filter_26==False)\n",
    "     & (url_filter_27==False)\n",
    "     & (url_filter_28==False)\n",
    "     & (url_filter_29==False)\n",
    "     & (url_filter_30==False),'URL_Cleaned_v2']= df['new_col']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_Series(msg_list):\n",
    "    len_list = len(msg_list)\n",
    "    return(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['url_len'] = df['URL_Cleaned_v2'].apply(len_Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth' ,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['URL_Cleaned_v2'].head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_checks[df_checks.url_len > 1].count()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Anacoda: pip install phonenumbers\n",
    "import phonenumbers\n",
    "\n",
    "x=df['MSG_Cleaned']\n",
    "\n",
    "def phone_cleaner(x):\n",
    "    for match in phonenumbers.PhoneNumberMatcher(x,\"US\"):\n",
    "        return phonenumbers.format_number(match.number, phonenumbers.PhoneNumberFormat.E164)\n",
    "        # print(match)\n",
    "\n",
    "df['Phone Number'] = x.apply(phone_cleaner).astype(str)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_filter_1 = (df[\"Phone Number\"].astype(str) == 'None')\n",
    "\n",
    "df['Phone_Cleaned']=\"\"  # Create one new column to store only valid emails\n",
    "df.loc[(phone_filter_1==False),'Phone_Cleaned']= df['Phone Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: What % of messages containing marketing promo info (coupon,x% off, promo)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Discount']=df['MSG_Cleaned'].astype(str).str.contains(\"% off|\\d off|dollar off|percent off|percentage off|discount|buy \\d get \\d free\",case=False)\n",
    "df['Coupon']=df['MSG_Cleaned'].astype(str).str.contains(\"coupon\",case=False)\n",
    "df['Promo Code']=df['MSG_Cleaned'].astype(str).str.contains(\"promo code\",case=False)\n",
    "df['Marketing_Overall']=df['MSG_Cleaned'].astype(str).str.contains(\"% off|\\d off|dollar off|percent off|percentage off|discount|buy \\d get \\d free|coupon|promo code\",case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount, x% off\n",
    "df['Discount_Cleaned']=\"\"\n",
    "# discount_filter_1 = df['MSG_Cleaned'].astype(str).str.contains(\"Discount $\",case=False)\n",
    "# df.loc[(discount_filter_1==False),'Discount_Cleaned'] = 'Has discount'\n",
    "df.loc[df['Discount']==True,'Discount_Cleaned'] = 'Has discount'\n",
    "df.loc[df['Discount_Cleaned']!=\"Has discount\",'Discount_Cleaned'] = 'Has no discount'\n",
    "\n",
    "\n",
    "# Coupon\n",
    "df['Coupon_Cleaned']=\"\"\n",
    "# coupon_filter_1 = df['MSG_Cleaned'].astype(str).str.contains(pat='',case=False) \n",
    "df.loc[df['Coupon']==True,'Coupon_Cleaned'] = 'Has coupon'\n",
    "df.loc[df['Coupon_Cleaned']!=\"Has coupon\",'Coupon_Cleaned'] = 'Has no coupon'\n",
    "\n",
    "\n",
    "# Promo code\n",
    "df['Promo Code_Cleaned']=\"\"\n",
    "# promo_code_filter_1 = df['MSG_Cleaned'].astype(str).str.contains(pat='':',case=False) \n",
    "df.loc[df['Promo Code']==True,'Promo Code_Cleaned'] = 'Has promo code'\n",
    "df.loc[df['Promo Code_Cleaned']!=\"Has promo code\",'Promo Code_Cleaned'] = 'Has no promo code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall\n",
    "df['Marketing_Cleaned']=\"\"\n",
    "\n",
    "df.loc[\n",
    "       (df['Discount_Cleaned'] == 'Has discount')\n",
    "      |(df['Coupon_Cleaned'] == 'Has coupon')\n",
    "      |(df['Promo Code_Cleaned'] == 'Has promo code'),'Marketing_Cleaned']= 'Has at least 1 promo info'\n",
    "\n",
    "df.loc[\n",
    "       (df['Discount_Cleaned'] != 'Has discount')\n",
    "      &(df['Coupon_Cleaned'] != 'Has coupon')\n",
    "      &(df['Promo Code_Cleaned'] != 'Has promo code'),'Marketing_Cleaned']= 'Has no promo info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_discount_pct = pd.DataFrame(df.groupby('Discount_Cleaned')['MSG_Cleaned'].count()/df['MSG_Cleaned'].count())\n",
    "df_discount_pct = df_discount_pct.T#.style.format('{:,.1%}')\n",
    "df_discount_pct            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
